{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017698,
     "end_time": "2021-07-26T08:53:07.621543",
     "exception": false,
     "start_time": "2021-07-26T08:53:07.603845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## You're here! \n",
    "Welcome to your first competition in the [ITI's AI Pro training program](https://ai.iti.gov.eg/epita/ai-engineer/)! We hope you enjoy and learn as much as we did prepairing this competition.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the competition, it's required to predict the `Severity` of a car crash given info about the crash, e.g., location.\n",
    "\n",
    "This is the getting started notebook. Things are kept simple so that it's easier to understand the steps and modify it.\n",
    "\n",
    "Feel free to `Fork` this notebook and share it with your modifications **OR** use it to create your submissions.\n",
    "\n",
    "### Prerequisites\n",
    "You should know how to use python and a little bit of Machine Learning. You can apply the techniques you learned in the training program and submit the new solutions! \n",
    "\n",
    "### Checklist\n",
    "You can participate in this competition the way you perefer. However, I recommend following these steps if this is your first time joining a competition on Kaggle.\n",
    "\n",
    "* Fork this notebook and run the cells in order.\n",
    "* Submit this solution.\n",
    "* Make changes to the data processing step as you see fit.\n",
    "* Submit the new solutions.\n",
    "\n",
    "*You can submit up to 5 submissions per day. You can select only one of the submission you make to be considered in the final ranking.*\n",
    "\n",
    "\n",
    "Don't hesitate to leave a comment or contact me if you have any question!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015863,
     "end_time": "2021-07-26T08:53:07.654193",
     "exception": false,
     "start_time": "2021-07-26T08:53:07.638330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import the libraries\n",
    "\n",
    "We'll use `pandas` to load and manipulate the data. Other libraries will be imported in the relevant sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-26T08:53:07.690745Z",
     "iopub.status.busy": "2021-07-26T08:53:07.689592Z",
     "iopub.status.idle": "2021-07-26T08:53:07.698965Z",
     "shell.execute_reply": "2021-07-26T08:53:07.699449Z",
     "shell.execute_reply.started": "2021-07-26T08:49:48.972746Z"
    },
    "papermill": {
     "duration": 0.029328,
     "end_time": "2021-07-26T08:53:07.699750",
     "exception": false,
     "start_time": "2021-07-26T08:53:07.670422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016192,
     "end_time": "2021-07-26T08:53:07.733129",
     "exception": false,
     "start_time": "2021-07-26T08:53:07.716937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Exploratory Data Analysis\n",
    "In this step, one should load the data and analyze it. However, I'll load the data and do minimal analysis. You are encouraged to do thorough analysis!\n",
    "\n",
    "Let's load the data using `pandas` and have a look at the generated `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T08:53:07.769396Z",
     "iopub.status.busy": "2021-07-26T08:53:07.768606Z",
     "iopub.status.idle": "2021-07-26T08:53:07.928723Z",
     "shell.execute_reply": "2021-07-26T08:53:07.929226Z",
     "shell.execute_reply.started": "2021-07-26T08:49:48.998869Z"
    },
    "papermill": {
     "duration": 0.180045,
     "end_time": "2021-07-26T08:53:07.929398",
     "exception": false,
     "start_time": "2021-07-26T08:53:07.749353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is (6407, 16).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '/kaggle/input/car-crashes-severity-prediction/'\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "print(\"The shape of the dataset is {}.\\n\\n\".format(df.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016789,
     "end_time": "2021-07-26T08:53:07.963620",
     "exception": false,
     "start_time": "2021-07-26T08:53:07.946831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We've got 6407 examples in the dataset with 14 featues, 1 ID, and the `Severity` of the crash.\n",
    "\n",
    "By looking at the features and a sample from the data, the features look of numerical and catogerical types. What about some descriptive statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T08:53:08.011112Z",
     "iopub.status.busy": "2021-07-26T08:53:08.010439Z",
     "iopub.status.idle": "2021-07-26T08:53:08.033266Z",
     "shell.execute_reply": "2021-07-26T08:53:08.033728Z",
     "shell.execute_reply.started": "2021-07-26T08:49:49.179309Z"
    },
    "papermill": {
     "duration": 0.053119,
     "end_time": "2021-07-26T08:53:08.033920",
     "exception": false,
     "start_time": "2021-07-26T08:53:07.980801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6407.000000</td>\n",
       "      <td>6407.000000</td>\n",
       "      <td>6407.000000</td>\n",
       "      <td>6407.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.765653</td>\n",
       "      <td>-122.405990</td>\n",
       "      <td>0.135189</td>\n",
       "      <td>2.293429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032555</td>\n",
       "      <td>0.028275</td>\n",
       "      <td>0.396360</td>\n",
       "      <td>0.521225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>37.609619</td>\n",
       "      <td>-122.510440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.737096</td>\n",
       "      <td>-122.412210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.768238</td>\n",
       "      <td>-122.404835</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.787813</td>\n",
       "      <td>-122.392477</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>37.825626</td>\n",
       "      <td>-122.349734</td>\n",
       "      <td>6.820000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Lat          Lng  Distance(mi)     Severity\n",
       "count  6407.000000  6407.000000   6407.000000  6407.000000\n",
       "mean     37.765653  -122.405990      0.135189     2.293429\n",
       "std       0.032555     0.028275      0.396360     0.521225\n",
       "min      37.609619  -122.510440      0.000000     1.000000\n",
       "25%      37.737096  -122.412210      0.000000     2.000000\n",
       "50%      37.768238  -122.404835      0.000000     2.000000\n",
       "75%      37.787813  -122.392477      0.041000     3.000000\n",
       "max      37.825626  -122.349734      6.820000     4.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns='ID').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018119,
     "end_time": "2021-07-26T08:53:08.069652",
     "exception": false,
     "start_time": "2021-07-26T08:53:08.051533",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The output shows desciptive statistics for the numerical features, `Lat`, `Lng`, `Distance(mi)`, and `Severity`. I'll use the numerical features to demonstrate how to train the model and make submissions. **However you shouldn't use the numerical features only to make the final submission if you want to make it to the top of the leaderboard.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017866,
     "end_time": "2021-07-26T08:53:08.105771",
     "exception": false,
     "start_time": "2021-07-26T08:53:08.087905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Splitting\n",
    "\n",
    "Now it's time to split the dataset for the training step. Typically the dataset is split into 3 subsets, namely, the training, validation and test sets. In our case, the test set is already predefined. So we'll split the \"training\" set into training and validation sets with 0.8:0.2 ratio. \n",
    "\n",
    "*Note: a good way to generate reproducible results is to set the seed to the algorithms that depends on randomization. This is done with the argument `random_state` in the following command* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017287,
     "end_time": "2021-07-26T08:53:09.132145",
     "exception": false,
     "start_time": "2021-07-26T08:53:09.114858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As pointed out eariler, I'll use the numerical features to train the classifier. **However, you shouldn't use the numerical features only to make the final submission if you want to make it to the top of the leaderboard.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6407 entries, 0 to 6406\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ID            6407 non-null   int64  \n",
      " 1   Lat           6407 non-null   float64\n",
      " 2   Lng           6407 non-null   float64\n",
      " 3   Bump          6407 non-null   bool   \n",
      " 4   Distance(mi)  6407 non-null   float64\n",
      " 5   Crossing      6407 non-null   bool   \n",
      " 6   Give_Way      6407 non-null   bool   \n",
      " 7   Junction      6407 non-null   bool   \n",
      " 8   No_Exit       6407 non-null   bool   \n",
      " 9   Railway       6407 non-null   bool   \n",
      " 10  Roundabout    6407 non-null   bool   \n",
      " 11  Stop          6407 non-null   bool   \n",
      " 12  Amenity       6407 non-null   bool   \n",
      " 13  Side          6407 non-null   object \n",
      " 14  Severity      6407 non-null   int64  \n",
      " 15  timestamp     6407 non-null   object \n",
      "dtypes: bool(9), float64(3), int64(2), object(2)\n",
      "memory usage: 406.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import codecs\n",
    "\n",
    "with codecs.open('holidays.xml', 'r', encoding='utf8') as f:\n",
    "    tt = f.read()\n",
    "def xml2df(xml_data):\n",
    "    root = ET.XML(xml_data)\n",
    "    all_records = []\n",
    "    for i, child in enumerate(root):\n",
    "        record = {}\n",
    "        for sub_child in child:\n",
    "            record[sub_child.tag] = sub_child.text\n",
    "        all_records.append(record)\n",
    "    return pd.DataFrame(all_records)\n",
    "\n",
    "\n",
    "df_xml = xml2df(tt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T08:53:09.175468Z",
     "iopub.status.busy": "2021-07-26T08:53:09.174494Z",
     "iopub.status.idle": "2021-07-26T08:53:09.177608Z",
     "shell.execute_reply": "2021-07-26T08:53:09.176997Z",
     "shell.execute_reply.started": "2021-07-26T08:49:50.396397Z"
    },
    "papermill": {
     "duration": 0.02815,
     "end_time": "2021-07-26T08:53:09.177746",
     "exception": false,
     "start_time": "2021-07-26T08:53:09.149596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9841 entries, 0 to 9840\n",
      "Data columns (total 26 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ID                 9841 non-null   int64  \n",
      " 1   Lat                9841 non-null   float64\n",
      " 2   Lng                9841 non-null   float64\n",
      " 3   Bump               9841 non-null   bool   \n",
      " 4   Distance(mi)       9841 non-null   float64\n",
      " 5   Crossing           9841 non-null   bool   \n",
      " 6   Give_Way           9841 non-null   bool   \n",
      " 7   Junction           9841 non-null   bool   \n",
      " 8   No_Exit            9841 non-null   bool   \n",
      " 9   Railway            9841 non-null   bool   \n",
      " 10  Roundabout         9841 non-null   bool   \n",
      " 11  Stop               9841 non-null   bool   \n",
      " 12  Amenity            9841 non-null   bool   \n",
      " 13  Side               9841 non-null   object \n",
      " 14  Severity           9841 non-null   int64  \n",
      " 15  timestamp          9841 non-null   object \n",
      " 16  newcol             9841 non-null   object \n",
      " 17  Hour               9841 non-null   int64  \n",
      " 18  Weather_Condition  9841 non-null   object \n",
      " 19  Wind_Chill(F)      7265 non-null   float64\n",
      " 20  Precipitation(in)  7538 non-null   float64\n",
      " 21  Temperature(F)     9841 non-null   float64\n",
      " 22  Humidity(%)        9841 non-null   float64\n",
      " 23  Wind_Speed(mph)    9398 non-null   float64\n",
      " 24  Visibility(mi)     9841 non-null   float64\n",
      " 25  Selected           9841 non-null   object \n",
      "dtypes: bool(9), float64(9), int64(3), object(5)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv( 'weather-sfcsv.csv')\n",
    "\n",
    "#print(\"The shape of the dataset is {}.\\n\\n\".format(df2.shape))\n",
    "df2[\"newcol\"] =df2[\"Year\"].astype(str)+ \"-\"+ df2[\"Month\"].astype(str) +\"-\" + df2[\"Day\"].astype(str) \n",
    "df2=df2.drop(columns=['Year','Day','Month'])\n",
    "df['newcol']= df['timestamp'].map(lambda x: str(x)[:10])\n",
    "\n",
    "df=pd.merge(df, df2, on='newcol')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xml['holiday']= df_xml['description']\n",
    "df['holiday']= df['timestamp'].map(lambda x: str(x)[:10])\n",
    "df=pd.merge(df, df_xml, on='holiday' ,how='left')\n",
    "\n",
    "df=df.drop(columns=['date','holiday'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = df['description'].astype('category').cat.categories.tolist()\n",
    "replace_map_comp = {'description' : {k: v for k,v in zip(labels,[1]*(len(labels)+1))}}\n",
    "df2.replace(replace_map_comp, inplace=True)\n",
    "\n",
    "df.fillna({'description':0}, inplace=True)\n",
    "\n",
    "labels = df['Weather_Condition'].astype('category').cat.categories.tolist()\n",
    "replace_map_comp = {'Weather_Condition' : {k: v for k,v in zip(labels,list(range(0,len(labels)+1)))}}\n",
    "df.replace(replace_map_comp, inplace=True)\n",
    "\n",
    "labels = df['Side'].astype('category').cat.categories.tolist()\n",
    "replace_map_comp = {'Side' : {k: v for k,v in zip(labels,list(range(0,len(labels)+1)))}}\n",
    "df.replace(replace_map_comp, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9841 entries, 0 to 9840\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ID                 9841 non-null   int64  \n",
      " 1   Lat                9841 non-null   float64\n",
      " 2   Lng                9841 non-null   float64\n",
      " 3   Bump               9841 non-null   bool   \n",
      " 4   Distance(mi)       9841 non-null   float64\n",
      " 5   Crossing           9841 non-null   bool   \n",
      " 6   Give_Way           9841 non-null   bool   \n",
      " 7   Junction           9841 non-null   bool   \n",
      " 8   No_Exit            9841 non-null   bool   \n",
      " 9   Railway            9841 non-null   bool   \n",
      " 10  Roundabout         9841 non-null   bool   \n",
      " 11  Stop               9841 non-null   bool   \n",
      " 12  Amenity            9841 non-null   bool   \n",
      " 13  Side               9841 non-null   int64  \n",
      " 14  Severity           9841 non-null   int64  \n",
      " 15  timestamp          9841 non-null   object \n",
      " 16  newcol             9841 non-null   object \n",
      " 17  Hour               9841 non-null   int64  \n",
      " 18  Weather_Condition  9841 non-null   int64  \n",
      " 19  Wind_Chill(F)      9841 non-null   float64\n",
      " 20  Precipitation(in)  9841 non-null   float64\n",
      " 21  Temperature(F)     9841 non-null   float64\n",
      " 22  Humidity(%)        9841 non-null   float64\n",
      " 23  Wind_Speed(mph)    9841 non-null   float64\n",
      " 24  Visibility(mi)     9841 non-null   float64\n",
      " 25  Selected           9841 non-null   object \n",
      " 26  description        9841 non-null   int64  \n",
      "dtypes: bool(9), float64(9), int64(6), object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df=df.fillna(df.mean())\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9841 entries, 0 to 9840\n",
      "Data columns (total 27 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   ID                 9841 non-null   int64  \n",
      " 1   Lat                9841 non-null   float64\n",
      " 2   Lng                9841 non-null   float64\n",
      " 3   Bump               9841 non-null   bool   \n",
      " 4   Distance(mi)       9841 non-null   float64\n",
      " 5   Crossing           9841 non-null   bool   \n",
      " 6   Give_Way           9841 non-null   bool   \n",
      " 7   Junction           9841 non-null   bool   \n",
      " 8   No_Exit            9841 non-null   bool   \n",
      " 9   Railway            9841 non-null   bool   \n",
      " 10  Roundabout         9841 non-null   bool   \n",
      " 11  Stop               9841 non-null   bool   \n",
      " 12  Amenity            9841 non-null   bool   \n",
      " 13  Side               9841 non-null   int64  \n",
      " 14  Severity           9841 non-null   int64  \n",
      " 15  timestamp          9841 non-null   object \n",
      " 16  newcol             9841 non-null   object \n",
      " 17  Hour               9841 non-null   int64  \n",
      " 18  Weather_Condition  9841 non-null   int64  \n",
      " 19  Wind_Chill(F)      9841 non-null   float64\n",
      " 20  Precipitation(in)  9841 non-null   float64\n",
      " 21  Temperature(F)     9841 non-null   float64\n",
      " 22  Humidity(%)        9841 non-null   float64\n",
      " 23  Wind_Speed(mph)    9841 non-null   float64\n",
      " 24  Visibility(mi)     9841 non-null   float64\n",
      " 25  Selected           9841 non-null   object \n",
      " 26  description        9841 non-null   int64  \n",
      "dtypes: bool(9), float64(9), int64(6), object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "df.to_csv('oba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T08:53:08.147557Z",
     "iopub.status.busy": "2021-07-26T08:53:08.146862Z",
     "iopub.status.idle": "2021-07-26T08:53:09.096491Z",
     "shell.execute_reply": "2021-07-26T08:53:09.095825Z",
     "shell.execute_reply.started": "2021-07-26T08:49:49.218084Z"
    },
    "papermill": {
     "duration": 0.973139,
     "end_time": "2021-07-26T08:53:09.096631",
     "exception": false,
     "start_time": "2021-07-26T08:53:08.123492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42) # Try adding `stratify` here\n",
    "\n",
    "X_train = train_df.drop(columns=['ID', 'Severity'])\n",
    "y_train = train_df['Severity']\n",
    "\n",
    "X_val = val_df.drop(columns=['ID', 'Severity'])\n",
    "y_val = val_df['Severity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['Lat', 'Lng', 'Distance(mi)','Crossing','Junction' ,'Railway' ,'Roundabout' ,'Stop' ,'Amenity','Side','Weather_Condition', 'Wind_Chill(F)', 'Precipitation(in)', 'Temperature(F)', 'Humidity(%)', 'Wind_Speed(mph)', 'Visibility(mi)','Hour','description']]\n",
    "X_val = X_val[['Lat', 'Lng', 'Distance(mi)','Crossing','Junction' ,'Railway' ,'Roundabout' ,'Stop' ,'Amenity','Side','Weather_Condition', 'Wind_Chill(F)', 'Precipitation(in)', 'Temperature(F)', 'Humidity(%)', 'Wind_Speed(mph)', 'Visibility(mi)','Hour','description']]\n",
    "\n",
    "#X_train = X_train[['Lat', 'Lng','Distance(mi)','Crossing','Junction' ,'Stop' ,'Amenity','Side', 'Wind_Chill(F)', 'Precipitation(in)', 'Visibility(mi)','Hour','description']]\n",
    "#X_val = X_val[['Lat', 'Lng','Distance(mi)','Crossing','Junction' ,'Stop' ,'Amenity','Side', 'Wind_Chill(F)', 'Precipitation(in)',  'Visibility(mi)','Hour','description']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0174,
     "end_time": "2021-07-26T08:53:09.212653",
     "exception": false,
     "start_time": "2021-07-26T08:53:09.195253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Training\n",
    "\n",
    "Let's train a model with the data! We'll train a Random Forest Classifier to demonstrate the process of making submissions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T08:53:09.252761Z",
     "iopub.status.busy": "2021-07-26T08:53:09.252050Z",
     "iopub.status.idle": "2021-07-26T08:53:09.719240Z",
     "shell.execute_reply": "2021-07-26T08:53:09.719725Z",
     "shell.execute_reply.started": "2021-07-26T08:49:50.409089Z"
    },
    "papermill": {
     "duration": 0.489771,
     "end_time": "2021-07-26T08:53:09.719921",
     "exception": false,
     "start_time": "2021-07-26T08:53:09.230150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create an instance of the classifier\n",
    "classifier = RandomForestClassifier(max_depth=30, random_state=0)\n",
    "\n",
    "# Train the classifier\n",
    "classifier = classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017124,
     "end_time": "2021-07-26T08:53:09.754447",
     "exception": false,
     "start_time": "2021-07-26T08:53:09.737323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let's test our classifier on the validation dataset and see the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T08:53:09.792892Z",
     "iopub.status.busy": "2021-07-26T08:53:09.791949Z",
     "iopub.status.idle": "2021-07-26T08:53:09.817931Z",
     "shell.execute_reply": "2021-07-26T08:53:09.818433Z",
     "shell.execute_reply.started": "2021-07-26T08:49:50.960998Z"
    },
    "papermill": {
     "duration": 0.046625,
     "end_time": "2021-07-26T08:53:09.818598",
     "exception": false,
     "start_time": "2021-07-26T08:53:09.771973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the classifier on the validation set is  0.9512442864398172\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the classifier on the validation set is \", (classifier.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017598,
     "end_time": "2021-07-26T08:53:09.853858",
     "exception": false,
     "start_time": "2021-07-26T08:53:09.836260",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Well. That's a good start, right? A classifier that predicts all examples' `Severity` as 2 will get around 0.63. You should get better score as you add more features and do better data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017288,
     "end_time": "2021-07-26T08:53:09.888842",
     "exception": false,
     "start_time": "2021-07-26T08:53:09.871554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission File Generation\n",
    "\n",
    "We have built a model and we'd like to submit our predictions on the test set! In order to do that, we'll load the test set, predict the class and save the submission file. \n",
    "\n",
    "First, we'll load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T08:53:09.928931Z",
     "iopub.status.busy": "2021-07-26T08:53:09.928263Z",
     "iopub.status.idle": "2021-07-26T08:53:09.962800Z",
     "shell.execute_reply": "2021-07-26T08:53:09.962287Z",
     "shell.execute_reply.started": "2021-07-26T08:49:51.000865Z"
    },
    "papermill": {
     "duration": 0.056458,
     "end_time": "2021-07-26T08:53:09.962962",
     "exception": false,
     "start_time": "2021-07-26T08:53:09.906504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "      <th>Bump</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>Crossing</th>\n",
       "      <th>Give_Way</th>\n",
       "      <th>Junction</th>\n",
       "      <th>No_Exit</th>\n",
       "      <th>Railway</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Amenity</th>\n",
       "      <th>Side</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6407</td>\n",
       "      <td>37.786060</td>\n",
       "      <td>-122.390900</td>\n",
       "      <td>False</td>\n",
       "      <td>0.039</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>R</td>\n",
       "      <td>2016-04-04 19:20:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6408</td>\n",
       "      <td>37.769609</td>\n",
       "      <td>-122.415057</td>\n",
       "      <td>False</td>\n",
       "      <td>0.202</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>R</td>\n",
       "      <td>2020-10-28 11:51:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6409</td>\n",
       "      <td>37.807495</td>\n",
       "      <td>-122.476021</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>R</td>\n",
       "      <td>2019-09-09 07:36:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6410</td>\n",
       "      <td>37.761818</td>\n",
       "      <td>-122.405869</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>R</td>\n",
       "      <td>2019-08-06 15:46:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6411</td>\n",
       "      <td>37.732350</td>\n",
       "      <td>-122.414100</td>\n",
       "      <td>False</td>\n",
       "      <td>0.670</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>R</td>\n",
       "      <td>2018-10-17 09:54:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID        Lat         Lng   Bump  Distance(mi)  Crossing  Give_Way  \\\n",
       "0  6407  37.786060 -122.390900  False         0.039     False     False   \n",
       "1  6408  37.769609 -122.415057  False         0.202     False     False   \n",
       "2  6409  37.807495 -122.476021  False         0.000     False     False   \n",
       "3  6410  37.761818 -122.405869  False         0.000     False     False   \n",
       "4  6411  37.732350 -122.414100  False         0.670     False     False   \n",
       "\n",
       "   Junction  No_Exit  Railway  Roundabout   Stop  Amenity Side  \\\n",
       "0      True    False    False       False  False    False    R   \n",
       "1     False    False    False       False  False    False    R   \n",
       "2     False    False    False       False  False    False    R   \n",
       "3      True    False    False       False  False    False    R   \n",
       "4     False    False    False       False  False    False    R   \n",
       "\n",
       "             timestamp  \n",
       "0  2016-04-04 19:20:31  \n",
       "1  2020-10-28 11:51:00  \n",
       "2  2019-09-09 07:36:45  \n",
       "3  2019-08-06 15:46:25  \n",
       "4  2018-10-17 09:54:58  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018225,
     "end_time": "2021-07-26T08:53:09.999902",
     "exception": false,
     "start_time": "2021-07-26T08:53:09.981677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Note that the test set has the same features and doesn't have the `Severity` column.\n",
    "At this stage one must **NOT** forget to apply the same processing done on the training set on the features of the test set.\n",
    "\n",
    "Now we'll add `Severity` column to the test `DataFrame` and add the values of the predicted class to it.\n",
    "\n",
    "**I'll select the numerical features here as I did in the training set. DO NOT forget to change this step as you change the preprocessing of the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T08:53:10.048128Z",
     "iopub.status.busy": "2021-07-26T08:53:10.047413Z",
     "iopub.status.idle": "2021-07-26T08:53:10.087261Z",
     "shell.execute_reply": "2021-07-26T08:53:10.086743Z",
     "shell.execute_reply.started": "2021-07-26T08:49:51.059979Z"
    },
    "papermill": {
     "duration": 0.068954,
     "end_time": "2021-07-26T08:53:10.087402",
     "exception": false,
     "start_time": "2021-07-26T08:53:10.018448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 3 features, but DecisionTreeClassifier is expecting 19 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-85d2bff04c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Lng'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Distance(mi)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_test_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Severity'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_predicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[1;32m    403\u001b[0m                                     reset=False)\n\u001b[1;32m    404\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3 features, but DecisionTreeClassifier is expecting 19 features as input."
     ]
    }
   ],
   "source": [
    "X_test = test_df.drop(columns=['ID'])\n",
    "\n",
    "# You should update/remove the next line once you change the features used for training\n",
    "X_test = X_test[['Lat', 'Lng', 'Distance(mi)']]\n",
    "\n",
    "y_test_predicted = classifier.predict(X_test)\n",
    "\n",
    "test_df['Severity'] = y_test_predicted\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01871,
     "end_time": "2021-07-26T08:53:10.125107",
     "exception": false,
     "start_time": "2021-07-26T08:53:10.106397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we're ready to generate the submission file. The submission file needs the columns `ID` and `Severity` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-26T08:53:10.170340Z",
     "iopub.status.busy": "2021-07-26T08:53:10.169586Z",
     "iopub.status.idle": "2021-07-26T08:53:10.178420Z",
     "shell.execute_reply": "2021-07-26T08:53:10.177767Z",
     "shell.execute_reply.started": "2021-07-26T08:49:51.150554Z"
    },
    "papermill": {
     "duration": 0.034035,
     "end_time": "2021-07-26T08:53:10.178557",
     "exception": false,
     "start_time": "2021-07-26T08:53:10.144522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df[['ID', 'Severity']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018719,
     "end_time": "2021-07-26T08:53:10.216318",
     "exception": false,
     "start_time": "2021-07-26T08:53:10.197599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The remaining steps is to submit the generated file and are as follows. \n",
    "\n",
    "1. Press `Save Version` on the upper right corner of this notebook.\n",
    "2. Write a `Version Name` of your choice and choose `Save & Run All (Commit)` then click `Save`.\n",
    "3. Wait for the saved notebook to finish running the go to the saved notebook.\n",
    "4. Scroll down until you see the output files then select the `submission.csv` file and click `Submit`.\n",
    "\n",
    "Now your submission will be evaluated and your score will be updated on the leaderboard! CONGRATULATIONS!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018578,
     "end_time": "2021-07-26T08:53:10.254075",
     "exception": false,
     "start_time": "2021-07-26T08:53:10.235497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we have demonstrated the essential steps that one should do in order to get \"slightly\" familiar with the data and the submission process. We chose not to go into details in each step to keep the welcoming notebook simple and make a room for improvement.\n",
    "\n",
    "You're encourged to `Fork` the notebook, edit it, add your insights and use it to create your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.567547,
   "end_time": "2021-07-26T08:53:10.982372",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-26T08:52:59.414825",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
